{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Practice Lab Neural Network 1**"
      ],
      "metadata": {
        "id": "DdHga1dyRTp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Name** : Mayur Kapgate                \n",
        " **Roll Number** : 27   \n",
        " **PRN No.** : 202201040065                                   \n",
        " **Batch** : DL 2"
      ],
      "metadata": {
        "id": "e3thejDQRc5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network Implementation from Scratch**"
      ],
      "metadata": {
        "id": "ZpgFWTzlSR7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective** : Implement a simple feedforward neural network from scratch in Python without using\n",
        " any in-built deep learning libraries. This implementation will focus on basic components like\n",
        " forward pass, backward propagation (backpropagation), and training using gradient descent."
      ],
      "metadata": {
        "id": "97Y8Oww7SUb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Definition**"
      ],
      "metadata": {
        "id": "3NiK_8M4SbqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset** : We'll use the Iris dataset, a famous dataset with 150 samples of iris flowers classified into 3\n",
        "species.\n",
        "\n",
        " **Task**: The task is a multi-class classification problem, where we will classify the flowers into one of\n",
        "three species based on the features (sepal length, sepal width, petal length, and petal width)."
      ],
      "metadata": {
        "id": "QpysHAo9Taam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network Architecture** :"
      ],
      "metadata": {
        "id": "IdWnQZW9TlFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Input Layer** : 4 neurons (since there are 4 features).\n",
        "\n",
        " **Hidden Layer** : 10 neurons (this is a hyperparameter).\n",
        "\n",
        " **Output Layer** : 3 neurons (since we have 3 classes)."
      ],
      "metadata": {
        "id": "eqKK-nu4TsqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Methodology**"
      ],
      "metadata": {
        "id": "gh9lp7rwT6qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Activation Functions :**\n",
        "\n",
        " a. **Hidden layer:** ReLU (Rectified Linear Unit)\n",
        "\n",
        " b. **Output layer:** Softmax (for multi-class classification).\n",
        "\n",
        " c. **Loss Function:** Cross-Entropy Loss (because it's a classification problem).\n",
        "\n",
        "\n",
        " * **Optimization:** **Gradient Descent** (we'll use batch gradient descent here).\n",
        "\n",
        "* **Data Preprocessig:**\n",
        "\n",
        " a. We load the Iris dataset using **sklearn.datasets.load_iris**.\n",
        "\n",
        " b. Labels are one-hot encoded using **OneHotEncoder** because we have multiple classes.\n",
        "\n",
        " c. Features are standardized using **StandardScale**r to improve the training performance.\n",
        "\n",
        "* **Neural Network Initialization:** We define the number of neurons in each layer and initialize the weights (W1, W2) and biases (b1, b2) with small random values.\n",
        "\n",
        "* **Activation Functions:**\n",
        "\n",
        " a. **ReLU** is used for the hidden layer to introduce non-linearity.\n",
        "\n",
        " b. **Softmax** is used in the output layer for multi-class classification.\n",
        "\n",
        "* **Loss Function:** We use Cross-Entropy Loss which is appropriate for multi-class classification tasks.\n",
        "\n",
        "* **Gradient Descent (Backpropagation):** We compute the gradients of the loss with respect to the weights and biases and update the parameters using gradient descent.\n",
        "\n",
        "* **Training:** We train the model for 1000 epochs (you can adjust this) and print the loss every 100 epochs.\n",
        "\n",
        "* **Evaluation:** After training, we evaluate the model on both the training and test sets by computing\n",
        "accuracy"
      ],
      "metadata": {
        "id": "IxH2cLxsUAAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F1anGMmwWDOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network** Implementation from Scratch using **Iris Dataset**"
      ],
      "metadata": {
        "id": "_6hfzIcSSffR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "9JDCnKogR4C7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rx7tEzd7Q0Gq"
      },
      "outputs": [],
      "source": [
        "# Load Iris dataset\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link to the dataset :** https://www.kaggle.com/datasets/uciml/iris"
      ],
      "metadata": {
        "id": "ijitOhOgXofs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "yJpaU96pWjEV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the input features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "wmIOR90RWmWJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_one_hot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tLkvac5RWpLU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Parameters\n",
        "\n",
        "input_size = X_train.shape[1]  # 4 features\n",
        "hidden_size = 10  # 10 neurons in the hidden layer\n",
        "output_size = y_train.shape[1]  # 3 output classes"
      ],
      "metadata": {
        "id": "hoW34EsyWsNc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "W1 = np.random.randn(input_size, hidden_size) * 0.01  # Weight for input to hidden layer\n",
        "b1 = np.zeros((1, hidden_size))  # Bias for hidden layer\n",
        "\n",
        "W2 = np.random.randn(hidden_size, output_size) * 0.01  # Weight for hidden to output layer\n",
        "b2 = np.zeros((1, output_size))  # Bias for output layer"
      ],
      "metadata": {
        "id": "pbmKC_ICWvO6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions and their derivatives\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # For numerical stability\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    m = y_true.shape[0]\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-8)) / m  # Add small epsilon for numerical stability"
      ],
      "metadata": {
        "id": "8NCFmMDdWyAP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "\n",
        "def forward(X):\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = softmax(z2)\n",
        "    return a1, a2"
      ],
      "metadata": {
        "id": "om3hibetW6vH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass (Gradient Descent and Backpropagation)\n",
        "\n",
        "def backward(X, y, a1, a2):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Output layer error\n",
        "    dz2 = a2 - y\n",
        "    dW2 = np.dot(a1.T, dz2) / m\n",
        "    db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Hidden layer error\n",
        "    dz1 = np.dot(dz2, W2.T) * relu_derivative(a1)\n",
        "    dW1 = np.dot(X.T, dz1) / m\n",
        "    db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "    return dW1, db1, dW2, db2"
      ],
      "metadata": {
        "id": "WWT0NNVZW93x"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model using gradient descent\n",
        "\n",
        "def train(X_train, y_train, learning_rate=0.01, epochs=1000):\n",
        "    global W1, b1, W2, b2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        a1, a2 = forward(X_train)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = cross_entropy_loss(a2, y_train)\n",
        "\n",
        "        # Backward pass\n",
        "        dW1, db1, dW2, db2 = backward(X_train, y_train, a1, a2)\n",
        "\n",
        "        # Update the weights and biases using gradient descent\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "MGzUKO8HXA1d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "\n",
        "def predict(X):\n",
        "    _, a2 = forward(X)\n",
        "    return np.argmax(a2, axis=1)"
      ],
      "metadata": {
        "id": "Diqma87-XHmq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the network\n",
        "\n",
        "train(X_train, y_train, learning_rate=0.1, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAZZKKB-XK8K",
        "outputId": "b80a990b-3d14-473e-c6c7-3959507c482d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000, Loss: 1.0985\n",
            "Epoch 100/1000, Loss: 0.5751\n",
            "Epoch 200/1000, Loss: 0.2933\n",
            "Epoch 300/1000, Loss: 0.1786\n",
            "Epoch 400/1000, Loss: 0.1196\n",
            "Epoch 500/1000, Loss: 0.0927\n",
            "Epoch 600/1000, Loss: 0.0788\n",
            "Epoch 700/1000, Loss: 0.0707\n",
            "Epoch 800/1000, Loss: 0.0654\n",
            "Epoch 900/1000, Loss: 0.0618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "y_pred_train = predict(X_train)\n",
        "y_pred_test = predict(X_test)\n",
        "\n",
        "y_true_train = np.argmax(y_train, axis=1)\n",
        "y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "train_accuracy = np.mean(y_pred_train == y_true_train) * 100\n",
        "test_accuracy = np.mean(y_pred_test == y_true_test) * 100\n",
        "\n",
        "print(f\"\\nTrain Accuracy: {train_accuracy:.2f}%\")\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKknKGGyXNQM",
        "outputId": "61d4e908-1eb3-4f13-ae64-2bdabce395b0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 98.33%\n",
            "\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Declaration:**\n",
        "\n",
        " I, Mayur Kapgate, confirm that the work submitted in this assignment is my own and has been completed following academic integrity guidelines. The code is uploaded on my GitHub repository account, and the repository link is provided below :\n",
        "\n",
        " **GitHub Repository Link:** [Insert GitHub Link]\n",
        "\n",
        " **Signature:** Mayur Ashok Kapgate\n",
        "\n",
        " **Submission Checklist:**\n",
        "\n",
        " ● Codefile (Python Notebook or Script)\n",
        "\n",
        " ● Dataset or link to the dataset\n",
        "\n",
        " ● Visualizations (if applicable)\n",
        "\n",
        " ● Screenshots of model performance metrics\n",
        "\n",
        " ● ReadmeFile"
      ],
      "metadata": {
        "id": "FAYVr62FX9xz"
      }
    }
  ]
}